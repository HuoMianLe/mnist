#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MNISTæ¨¡å‹å›¾åƒè¯†åˆ«å·¥å…·
åŠŸèƒ½ï¼š
1. åŠ è½½./modelsæ–‡ä»¶å¤¹ä¸‹æŒ‡å®šçš„æ¨¡å‹
2. è¯†åˆ«./data/test/pngæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰å›¾ç‰‡æˆ–æŒ‡å®šå›¾ç‰‡
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import os
import glob
import argparse
import json
from datetime import datetime


# --- æ¨¡å‹å®šä¹‰ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰---
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()

        # å·ç§¯å±‚
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=1)
        self.bn1 = nn.BatchNorm2d(32)

        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1)
        self.bn2 = nn.BatchNorm2d(64)

        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)

        # æ± åŒ–å±‚
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # Dropoutå±‚
        self.dropout1 = nn.Dropout(0.25)
        self.dropout2 = nn.Dropout(0.5)

        # å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(128 * 3 * 3, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        # ç¬¬ä¸€ä¸ªå·ç§¯å—
        x = self.pool(F.relu(self.bn1(self.conv1(x))))

        # ç¬¬äºŒä¸ªå·ç§¯å—
        x = self.pool(F.relu(self.bn2(self.conv2(x))))

        # ç¬¬ä¸‰ä¸ªå·ç§¯å—
        x = self.pool(F.relu(self.bn3(self.conv3(x))))

        # å±•å¹³
        x = x.view(-1, 128 * 3 * 3)
        x = self.dropout1(x)

        # å…¨è¿æ¥å±‚
        x = F.relu(self.fc1(x))
        x = self.dropout2(x)
        x = F.relu(self.fc2(x))
        x = self.fc3(x)

        return x


class MNISTRecognizer:
    """MNISTæ•°å­—è¯†åˆ«å™¨"""

    def __init__(self, model_path=None):
        """
        åˆå§‹åŒ–è¯†åˆ«å™¨

        å‚æ•°:
            model_path (str): æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æœ€ä½³æ¨¡å‹
        """
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")

        # å›¾åƒé¢„å¤„ç†å˜æ¢ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        self.transform = transforms.Compose([
            transforms.Grayscale(num_output_channels=1),  # ç¡®ä¿æ˜¯ç°åº¦å›¾
            transforms.Resize((28, 28)),  # è°ƒæ•´åˆ°28x28
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))  # MNISTæ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®
        ])

        # åŠ è½½æ¨¡å‹
        self.model = self.load_model(model_path)

    def load_model(self, model_path=None):
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹

        å‚æ•°:
            model_path (str): æ¨¡å‹æ–‡ä»¶è·¯å¾„

        è¿”å›:
            torch.nn.Module: åŠ è½½çš„æ¨¡å‹
        """
        if model_path is None:
            # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹
            model_path = self.find_best_model()

        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")

        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = CNN()

        # åŠ è½½æ¨¡å‹å‚æ•°
        try:
            checkpoint = torch.load(model_path, map_location=self.device)
            model.load_state_dict(checkpoint)
            model.to(self.device)
            model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            return model
        except Exception as e:
            raise RuntimeError(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")

    def find_best_model(self):
        """
        è‡ªåŠ¨æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æ–‡ä»¶

        è¿”å›:
            str: æœ€ä½³æ¨¡å‹çš„è·¯å¾„
        """
        models_dir = "./models"

        # ä¼˜å…ˆé€‰æ‹©bestæ¨¡å‹
        best_model = os.path.join(models_dir, "best_mnist_cnn_model.pth")
        if os.path.exists(best_model):
            return best_model

        # å¦‚æœæ²¡æœ‰bestæ¨¡å‹ï¼Œé€‰æ‹©æœ€æ–°çš„epochæ¨¡å‹
        pattern = os.path.join(models_dir, "mnist_cnn_epoch_*.pth")
        model_files = glob.glob(pattern)

        if not model_files:
            raise FileNotFoundError("åœ¨./modelsç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")

        # æŒ‰epochæ•°å­—æ’åºï¼Œé€‰æ‹©æœ€å¤§çš„
        def extract_epoch(filename):
            try:
                epoch_str = filename.split("epoch_")[1].split(".pth")[0]
                return int(epoch_str)
            except:
                return 0

        latest_model = max(model_files, key=extract_epoch)
        return latest_model

    def list_available_models(self):
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶

        è¿”å›:
            list: å¯ç”¨æ¨¡å‹æ–‡ä»¶åˆ—è¡¨
        """
        models_dir = "./models"
        if not os.path.exists(models_dir):
            return []

        model_files = glob.glob(os.path.join(models_dir, "*.pth"))
        return sorted(model_files)

    def select_model_interactive(self):
        """
        äº¤äº’å¼é€‰æ‹©æ¨¡å‹

        è¿”å›:
            str: é€‰æ‹©çš„æ¨¡å‹è·¯å¾„
        """
        model_files = self.list_available_models()

        if not model_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
            return None

        print("\nğŸ“ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
        print("-" * 50)

        # æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨
        for i, model_file in enumerate(model_files, 1):
            filename = os.path.basename(model_file)
            file_size = os.path.getsize(model_file) / (1024*1024)  # MB

            # è·å–åˆ›å»ºæ—¶é—´
            create_time = os.path.getctime(model_file)
            create_time_str = datetime.fromtimestamp(
                create_time).strftime('%Y-%m-%d %H:%M:%S')

            # æ ‡è®°æœ€ä½³æ¨¡å‹
            is_best = "best" in filename.lower()
            mark = " â­ [æ¨è]" if is_best else ""

            print(
                f"   {i:2d}. {filename} ({file_size:.2f} MB) - {create_time_str}{mark}")

        print("-" * 50)

        while True:
            try:
                choice = input("è¯·é€‰æ‹©æ¨¡å‹ç¼–å· (è¾“å…¥æ•°å­—ï¼Œ0è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹): ").strip()

                if choice == '0':
                    # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹
                    return self.find_best_model()

                choice_num = int(choice)
                if 1 <= choice_num <= len(model_files):
                    selected_model = model_files[choice_num - 1]
                    print(f"âœ… å·²é€‰æ‹©æ¨¡å‹: {os.path.basename(selected_model)}")
                    return selected_model
                else:
                    print(f"âŒ è¯·è¾“å…¥ 0-{len(model_files)} ä¹‹é—´çš„æ•°å­—")

            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            except KeyboardInterrupt:
                print("\nâš ï¸  æ“ä½œè¢«å–æ¶ˆ")
                return None

    def predict_single_image(self, image_path):
        """
        è¯†åˆ«å•å¼ å›¾ç‰‡

        å‚æ•°:
            image_path (str): å›¾ç‰‡è·¯å¾„

        è¿”å›:
            tuple: (é¢„æµ‹ç±»åˆ«, ç½®ä¿¡åº¦, æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡)
        """
        try:
            # åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡
            image = Image.open(image_path)

            # å¦‚æœæ˜¯RGBAæ¨¡å¼ï¼Œè½¬æ¢ä¸ºRGB
            if image.mode == 'RGBA':
                # åˆ›å»ºç™½è‰²èƒŒæ™¯
                background = Image.new('RGB', image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1])
                image = background

            # åº”ç”¨å˜æ¢
            image_tensor = self.transform(image).unsqueeze(0)  # æ·»åŠ batchç»´åº¦
            image_tensor = image_tensor.to(self.device)

            # è¿›è¡Œé¢„æµ‹
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = F.softmax(outputs, dim=1)
                predicted_class = torch.argmax(outputs, dim=1).item()
                confidence = probabilities[0][predicted_class].item()

            return predicted_class, confidence, probabilities[0].cpu().numpy()

        except Exception as e:
            print(f"âŒ å¤„ç†å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {e}")
            return None, None, None

    def predict_multiple_images(self, images_dir, pattern="*.png"):
        """
        æ‰¹é‡è¯†åˆ«å›¾ç‰‡

        å‚æ•°:
            images_dir (str): å›¾ç‰‡ç›®å½•è·¯å¾„
            pattern (str): æ–‡ä»¶åŒ¹é…æ¨¡å¼

        è¿”å›:
            list: è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        # è·å–æ‰€æœ‰åŒ¹é…çš„å›¾ç‰‡æ–‡ä»¶
        search_pattern = os.path.join(images_dir, pattern)
        image_files = glob.glob(search_pattern)

        if not image_files:
            print(f"âš ï¸  åœ¨ç›®å½• {images_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡æ–‡ä»¶")
            return []

        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        print("=" * 60)

        results = []
        for i, img_path in enumerate(image_files, 1):
            filename = os.path.basename(img_path)
            print(f"[{i}/{len(image_files)}] æ­£åœ¨è¯†åˆ«: {filename}")

            predicted_class, confidence, probabilities = self.predict_single_image(
                img_path)

            if predicted_class is not None:
                result = {
                    'filename': filename,
                    'path': img_path,
                    'predicted_class': predicted_class,
                    'confidence': confidence,
                    'probabilities': probabilities
                }
                results.append(result)

                print(f"   ğŸ¯ é¢„æµ‹ç»“æœ: {predicted_class}")
                print(f"   ğŸ“Š ç½®ä¿¡åº¦: {confidence:.4f} ({confidence*100:.2f}%)")

                # æ˜¾ç¤ºçœŸå®æ ‡ç­¾ï¼ˆå¦‚æœæ–‡ä»¶ååŒ…å«æ ‡ç­¾ä¿¡æ¯ï¼‰
                true_label = self.extract_true_label(filename)
                if true_label is not None:
                    is_correct = predicted_class == true_label
                    status = "âœ… æ­£ç¡®" if is_correct else "âŒ é”™è¯¯"
                    print(f"   ğŸ·ï¸  çœŸå®æ ‡ç­¾: {true_label} - {status}")

                print("-" * 40)

        return results

    def extract_true_label(self, filename):

        # ä»æ–‡ä»¶åä¸­æå–çœŸå®æ ‡ç­¾
        # å‚æ•°: filename(str): æ–‡ä»¶å
        # è¿”å›: int or None: çœŸå®æ ‡ç­¾
        try:
            # å‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º number3_2.pngï¼Œæå–æ•°å­—2ï¼ˆä¸‹åˆ’çº¿åçš„æ•°å­—ï¼‰
            if filename.startswith('number') and '_' in filename:
                # åˆ†å‰²æ–‡ä»¶åï¼Œè·å–ä¸‹åˆ’çº¿åçš„éƒ¨åˆ†
                parts = filename.split('_')
                if len(parts) >= 2:
                    # è·å–ä¸‹åˆ’çº¿åçš„æ•°å­—éƒ¨åˆ†ï¼Œå»æ‰.pngåç¼€
                    label_str = parts[1].split('.')[0]
                    return int(label_str)
        except:
            pass
        return None

    def print_summary(self, results):
        """
        æ‰“å°è¯†åˆ«ç»“æœæ‘˜è¦

        å‚æ•°:
            results (list): è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        if not results:
            print("ğŸ“ æ²¡æœ‰è¯†åˆ«ç»“æœ")
            return

        print("\n" + "=" * 60)
        print("                   ğŸ“Š è¯†åˆ«ç»“æœæ‘˜è¦")
        print("=" * 60)

        total_images = len(results)
        correct_predictions = 0

        # ç»Ÿè®¡å‡†ç¡®ç‡
        for result in results:
            filename = result['filename']
            predicted = result['predicted_class']
            true_label = self.extract_true_label(filename)

            if true_label is not None and predicted == true_label:
                correct_predictions += 1

        print(f"ğŸ“ æ€»å›¾ç‰‡æ•°é‡: {total_images}")

        if correct_predictions > 0:
            accuracy = correct_predictions / total_images * 100
            print(
                f"ğŸ¯ è¯†åˆ«å‡†ç¡®ç‡: {correct_predictions}/{total_images} ({accuracy:.2f}%)")

        # ç»Ÿè®¡å„ç±»åˆ«çš„è¯†åˆ«æƒ…å†µ
        class_counts = {}
        for result in results:
            predicted = result['predicted_class']
            class_counts[predicted] = class_counts.get(predicted, 0) + 1

        print(f"\nğŸ“Š å„æ•°å­—è¯†åˆ«ç»Ÿè®¡:")
        for digit in sorted(class_counts.keys()):
            count = class_counts[digit]
            percentage = count / total_images * 100
            print(f"   æ•°å­— {digit}: {count} æ¬¡ ({percentage:.1f}%)")

        # æ˜¾ç¤ºæœ€é«˜å’Œæœ€ä½ç½®ä¿¡åº¦
        confidences = [r['confidence'] for r in results]
        if confidences:
            max_conf = max(confidences)
            min_conf = min(confidences)
            avg_conf = sum(confidences) / len(confidences)

            print(f"\nğŸ“ˆ ç½®ä¿¡åº¦ç»Ÿè®¡:")
            print(f"   æœ€é«˜ç½®ä¿¡åº¦: {max_conf:.4f} ({max_conf*100:.2f}%)")
            print(f"   æœ€ä½ç½®ä¿¡åº¦: {min_conf:.4f} ({min_conf*100:.2f}%)")
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.4f} ({avg_conf*100:.2f}%)")


def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("=" * 60)
    print("          ğŸ” MNISTæ•°å­—è¯†åˆ«å·¥å…· - äº¤äº’æ¨¡å¼")
    print("=" * 60)
    print("åŠŸèƒ½ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„CNNæ¨¡å‹è¯†åˆ«æ‰‹å†™æ•°å­—å›¾ç‰‡")
    print("æ”¯æŒçš„å‘½ä»¤ï¼š")
    print("  - è¾“å…¥å›¾ç‰‡è·¯å¾„ï¼šè¯†åˆ«å•å¼ å›¾ç‰‡")
    print("  - 'batch'ï¼šæ‰¹é‡è¯†åˆ«./data/test/png/ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡")
    print("  - 'list'ï¼šæ˜¾ç¤ºå¯ç”¨çš„æ¨¡å‹åˆ—è¡¨")
    print("  - 'select'ï¼šé€‰æ‹©ä¸åŒçš„æ¨¡å‹")
    print("  - 'model'ï¼šæŸ¥çœ‹å½“å‰ä½¿ç”¨çš„æ¨¡å‹")
    print("  - 'quit' æˆ– 'exit'ï¼šé€€å‡ºç¨‹åº")
    print("-" * 60)

    # åˆå§‹åŒ–è¯†åˆ«å™¨
    try:
        # å…ˆæ˜¾ç¤ºæ¨¡å‹é€‰æ‹©ç•Œé¢
        print("\nğŸ¯ è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹:")
        recognizer = MNISTRecognizer()
        model_path = recognizer.select_model_interactive()

        if model_path is None:
            print("âŒ æœªé€‰æ‹©æ¨¡å‹ï¼Œç¨‹åºé€€å‡º")
            return

        # é‡æ–°åˆå§‹åŒ–è¯†åˆ«å™¨ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹
        recognizer = MNISTRecognizer(model_path)
        current_model = os.path.basename(model_path)

    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–è¯†åˆ«å™¨å¤±è´¥: {e}")
        return

    while True:
        try:
            user_input = input(
                f"\nğŸ¯ è¯·è¾“å…¥å‘½ä»¤æˆ–å›¾ç‰‡è·¯å¾„ [å½“å‰æ¨¡å‹: {current_model}]: ").strip()

            # æ£€æŸ¥é€€å‡ºå‘½ä»¤
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼å†è§ï¼")
                break

            # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºç©º
            if not user_input:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„å‘½ä»¤æˆ–å›¾ç‰‡è·¯å¾„")
                continue

            # é€‰æ‹©æ¨¡å‹å‘½ä»¤
            if user_input.lower() == 'select':
                print("\nğŸ”„ é‡æ–°é€‰æ‹©æ¨¡å‹...")
                new_model_path = recognizer.select_model_interactive()
                if new_model_path and new_model_path != model_path:
                    try:
                        recognizer = MNISTRecognizer(new_model_path)
                        model_path = new_model_path
                        current_model = os.path.basename(model_path)
                        print(f"âœ… æ¨¡å‹åˆ‡æ¢æˆåŠŸ: {current_model}")
                    except Exception as e:
                        print(f"âŒ æ¨¡å‹åˆ‡æ¢å¤±è´¥: {e}")
                continue

            # æŸ¥çœ‹å½“å‰æ¨¡å‹å‘½ä»¤
            if user_input.lower() == 'model':
                print(f"\nğŸ“¦ å½“å‰ä½¿ç”¨æ¨¡å‹: {current_model}")
                print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
                file_size = os.path.getsize(model_path) / (1024*1024)
                create_time = os.path.getctime(model_path)
                create_time_str = datetime.fromtimestamp(
                    create_time).strftime('%Y-%m-%d %H:%M:%S')
                print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                print(f"ğŸ•’ åˆ›å»ºæ—¶é—´: {create_time_str}")
                continue

            # æ‰¹é‡å¤„ç†å‘½ä»¤
            if user_input.lower() == 'batch':
                print("\nğŸ”„ å¼€å§‹æ‰¹é‡è¯†åˆ«...")
                results = recognizer.predict_multiple_images(
                    "./data/test/png/")
                recognizer.print_summary(results)
                continue

            # æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨
            if user_input.lower() == 'list':
                models_dir = "./models"
                if os.path.exists(models_dir):
                    model_files = glob.glob(os.path.join(models_dir, "*.pth"))
                    print(f"\nğŸ“ å¯ç”¨æ¨¡å‹åˆ—è¡¨ ({models_dir}):")
                    for model_file in sorted(model_files):
                        filename = os.path.basename(model_file)
                        file_size = os.path.getsize(
                            model_file) / (1024*1024)  # MB
                        is_current = filename == current_model
                        mark = " âœ… [å½“å‰]" if is_current else ""
                        print(f"   ğŸ“¦ {filename} ({file_size:.2f} MB){mark}")
                else:
                    print("âŒ modelsç›®å½•ä¸å­˜åœ¨")
                continue

            # è¯†åˆ«å•å¼ å›¾ç‰‡
            if os.path.exists(user_input):
                print(f"\nğŸ” æ­£åœ¨è¯†åˆ«å›¾ç‰‡: {user_input}")
                print("-" * 40)

                predicted_class, confidence, probabilities = recognizer.predict_single_image(
                    user_input)

                if predicted_class is not None:
                    print(f"ğŸ¯ é¢„æµ‹ç»“æœ: {predicted_class}")
                    print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence:.4f} ({confidence*100:.2f}%)")

                    # æ˜¾ç¤ºæ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒ
                    print("\nğŸ“ˆ å„æ•°å­—çš„æ¦‚ç‡åˆ†å¸ƒ:")
                    for i, prob in enumerate(probabilities):
                        bar_length = int(prob * 20)  # ç®€å•çš„è¿›åº¦æ¡
                        bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
                        print(f"   æ•°å­— {i}: {bar} {prob:.4f} ({prob*100:.2f}%)")

                    # æ£€æŸ¥çœŸå®æ ‡ç­¾
                    filename = os.path.basename(user_input)
                    true_label = recognizer.extract_true_label(filename)
                    if true_label is not None:
                        is_correct = predicted_class == true_label
                        status = "âœ… æ­£ç¡®" if is_correct else "âŒ é”™è¯¯"
                        print(f"\nğŸ·ï¸  çœŸå®æ ‡ç­¾: {true_label} - {status}")
                else:
                    print("âŒ è¯†åˆ«å¤±è´¥")
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {user_input}")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='MNISTæ•°å­—è¯†åˆ«å·¥å…·')
    parser.add_argument('-m', '--model', help='æŒ‡å®šæ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-i', '--image', help='å•å¼ å›¾ç‰‡è·¯å¾„')
    parser.add_argument('-d', '--directory',
                        default='./data/test/png/', help='å›¾ç‰‡ç›®å½•è·¯å¾„')
    parser.add_argument('-b', '--batch', action='store_true', help='æ‰¹é‡å¤„ç†æ¨¡å¼')
    parser.add_argument('-p', '--pattern', default='*.png', help='æ–‡ä»¶åŒ¹é…æ¨¡å¼')
    parser.add_argument('-s', '--select', action='store_true', help='äº¤äº’å¼é€‰æ‹©æ¨¡å‹')

    args = parser.parse_args()

    try:
        # å¦‚æœæŒ‡å®šäº†äº¤äº’å¼é€‰æ‹©æ¨¡å‹
        if args.select:
            temp_recognizer = MNISTRecognizer()
            selected_model = temp_recognizer.select_model_interactive()
            if selected_model:
                args.model = selected_model
            else:
                print("âŒ æœªé€‰æ‹©æ¨¡å‹ï¼Œç¨‹åºé€€å‡º")
                return

        # åˆå§‹åŒ–è¯†åˆ«å™¨
        recognizer = MNISTRecognizer(args.model)

        if args.image:
            # å•å¼ å›¾ç‰‡è¯†åˆ«
            print(f"ğŸ” è¯†åˆ«å•å¼ å›¾ç‰‡: {args.image}")
            predicted_class, confidence, probabilities = recognizer.predict_single_image(
                args.image)

            if predicted_class is not None:
                print(f"ğŸ¯ é¢„æµ‹ç»“æœ: {predicted_class}")
                print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence:.4f} ({confidence*100:.2f}%)")

                # æ˜¾ç¤ºçœŸå®æ ‡ç­¾
                filename = os.path.basename(args.image)
                true_label = recognizer.extract_true_label(filename)
                if true_label is not None:
                    is_correct = predicted_class == true_label
                    status = "âœ… æ­£ç¡®" if is_correct else "âŒ é”™è¯¯"
                    print(f"ğŸ·ï¸  çœŸå®æ ‡ç­¾: {true_label} - {status}")
            else:
                print("âŒ è¯†åˆ«å¤±è´¥")

        elif args.batch:
            # æ‰¹é‡è¯†åˆ«
            print(f"ğŸ”„ æ‰¹é‡è¯†åˆ«ç›®å½•: {args.directory}")
            results = recognizer.predict_multiple_images(
                args.directory, args.pattern)
            recognizer.print_summary(results)

        else:
            # äº¤äº’æ¨¡å¼
            interactive_mode()

    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    import sys

    if len(sys.argv) > 1:
        # æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼
        main()
    else:
        # æ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œè¿›å…¥äº¤äº’æ¨¡å¼
        interactive_mode()
